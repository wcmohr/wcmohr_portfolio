### An investigation of the predictive value of Elo and Glicko-2 rating systems in professional tennis when compared with ranking points

#### Objective
The objective of this project is to determine how the Elo and Glicko-2 rating systems compare with ranking points when determining who will win a match.  Predictive accuracy will be the primary metric for determining the predictive power of the respective prediction methods.

#### Background
In tennis, ranking points determine a player's rank on the ATP tour.  [Ranking points](https://www.atptour.com/en/rankings/rankings-faq) are used to determine seeding and qualification for ATP events and are accumulated over a trailing 52 week period.  The ranking points system incentivizes players to play tournaments to maintain their ranking in addition to the tournament participation requirements of the ATP.  Elo and Glicko-2 rating systems maintain parameters for each player that allow for immediate pairwise comparisons between players as well as ordering of players according to ability.  The Elo rating system was developed by Arpad Elo for the US Chess Federation as replacement for the Harkness rating system.  Glicko-2 was developed by Mark Glickman as a theoretical extension of the Elo system and an improvement on his original Glicko system.  The Glicko-2 system most importantly allows for a confidence interval that accounts for the uncertainty of a player's true mean rating.  

#### Methods
In this analysis I separately apply the Elo and Glicko-2 rating system methodologies to professional match data from 1877 to 2022.  The data has been collected and curated for authenticity by Jeff Sackmann and has been made available on his tennis_atp [github repo](https://github.com/JeffSackmann/tennis_atp).  To generate Elo and Glicko-2 ratings for use in calculating win probabilities, I generated ratings after yearly batches of data that were associated with a timestamp.  Ratings and rating deviations carried over to the next batch, updated parameters for each player were calculated based on results, and a new snapshot in time of the ratings were generated.  Finally this data was organized and attached to each player in each match of the dataset for use in the modeling process.

The modeling process first required filtering to ensure that rank points and Elo and Glicko-2 parameters were available.  Then data was randomized to disassociate the outcome from the parameters, which had previously been grouped by 'winner' and 'loser'.  Next the results were analyzed and the modeling dataset was tweaked to account for Elo and Glicko-2 parameters having non-zero default values upon initialization.  Finally the impact of this change was observed.

#### Results
According to the accuracy metric, logistic regression with the weighted rank points differential performed the best with an accuracy of 64.3%.  On the same data, Elo was not close behind in this metric with an accuracy of 63%, though Glicko-2 came in a distant third with an accuracy of 60%.  After removing matches in which both players had default Glicko-2 and Elo ratings, the Elo accuracy improved slightly by .25% while the Glicko-2 accuracy improved by 1.7%.  The dataset size declined by 3% for Elo and 5% for Glicko-2.  The bright spot for these two rating systems came with the mean squared error analysis, where the mean squared error was .35 with logistic regressin but .23 for Elo and Glicko-2.

#### Conclusions
The Glicko-2 and Elo rating systems offered on the whole worse predictive accuracy but significantly better mean squared errors.  This lends to the potential in monte-carlo simulations of tournament outcomes as well as confidence weighted betting strategies.  The computational intestity of Glicko-2 was not rewarded in either metric when compared with the much more straightforward Elo algorithm.

#### Next Steps
To further solidify and flesh out the present analysis there are a number of avenues to pursue.  First, the Glicko-2 implementation can be investigated to determine if updating the source code according to recent updates in the algorithm by Mark Glickman solves the quirks seen in the present application that required contortionist workarounds. Second, identifying areas of the dataset that may offer a comparative advantage to Elo or Glicko-2, such as with players coming back after a haiatus or players present in many matches in the dataset.  Also, exploring applications of the mean squared error advantage in the areas of betting and tournament simulations could be fruitful.

More broadly, I could explore a broader set of predictive parameters for use in the modeling process such as weight and height differentials as well as time-series features such as win and loss streaks.  In addition, comparison with alternative graph-based algorithms such as PageRank could be instructive.